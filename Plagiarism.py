import streamlit as st
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate
from langchain_groq import ChatGroq
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_openai import ChatOpenAI
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader
from langchain.vectorstores import FAISS
import os
from dotenv import load_dotenv
import google.generativeai as genai
import pandas as pd
import json
from io import BytesIO
import tempfile
import webbrowser
import random
import streamlit_shadcn_ui as ui


load_dotenv()


HF_TOKEN = os.getenv('HF_TOKEN')
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# API keys
api_key = os.getenv('API_KEY')
GEMINI_API_KEY = os.getenv('GEMINI_API')
os.environ["GOOGLE_API_KEY"] = 'AIzaSyDzJdYXogH--ueNwQF3z9o85Ln-iuOmG_s'

#if "GOOGLE_API_KEY" not in os.environ:
    #os.environ["GOOGLE_API_KEY"] ="AIzaSyDzJdYXogH--ueNwQF3z9o85Ln-iuOmG_s"

llm = ChatGroq(groq_api_key=api_key, model_name="llama-3.1-8b-instant")
llm_2 = ChatGroq(groq_api_key=api_key, model_name="gemma2-9b-it")
llm3 = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash"
)

tabs = ["English", "French", "Spanish", "German"]
selected_tab = st.tabs(tabs)

option = st.selectbox(
    "Select Language of your choice",
    ("English",
    "Mandarin Chinese",
    "Spanish",
    "Hindi",
    "Arabic",
    "Bengali",
    "Portuguese",
    "Russian",
    "Japanese",
    "Punjabi",
    "German",
    "Korean",
    "French",
    "Turkish",
    "Vietnamese",
    "Italian",
    "Persian",
    "Swahili",
    "Tamil",
    "Urdu")
)

modes=st.selectbox(
    "Select mode of your choice",
    (  "Standard",       # Default mode, balances fluency and rewriting
    "Fluency",        # Focuses on improving grammar and fluency
    "Formal",         # Makes the text more professional and polished
    "Simple",         # Simplifies the text, suitable for better readability
    "Creative",       # Provides more diverse and imaginative rewrites
    "Expand",         # Increases the length of the text while maintaining meaning
    "Shorten"         # Reduces the length of the text while keeping the key message),
))


text = st.text_input("Enter the text you want to paraphrase")
file = st.file_uploader("Upload a file", type="pdf")


def detect_plagiarism(files,options):
    try:
        # Save uploaded file temporarily
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp_pdf:
            temp_pdf.write(files.getvalue())
            temp_pdf_path = temp_pdf.name

        # Load the PDF using PyPDFLoader
        loader = PyPDFLoader(temp_pdf_path)
        docs = loader.load()

    finally:
        # Remove the temporary file after processing
        if os.path.exists(temp_pdf_path):
            os.remove(temp_pdf_path)

    # Split text into chunks for embeddings
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=500)
    splits = text_splitter.split_documents(docs)

    # Create FAISS vectorstore
    vectorstore = FAISS.from_documents(splits, embeddings)
    retriever = vectorstore.as_retriever()

    # Define the system prompt for plagiarism detection
    system_prompt = (
        f"Analyze the following text in '{options}' and detect plagiarism. "
        "Check for matching phrases and sources, and suggest paraphrased alternatives for each plagiarized segment. "
        "Create a well-detailed report similar to those generated by Quillbot, Grammarly, or Turnitin. "
        "The report should include the following sections:\n\n"
        "1. **Plagiarism Overview**:\n"
        "   - Total Plagiarism Percentage\n"
        "   - Unique Content Percentage\n"
        "   - Word Count Analyzed\n\n"
        "2. **Detailed Matched Sources**:\n"
        "   - List of matched sources with URLs or references\n"
        "   - Percentage of match per source\n"
        "   - Number of sentences matched from each source\n\n"
        "3. **Highlighted Plagiarized Text**:\n"
        "   - Original text segments flagged as plagiarized\n"
        "   - Corresponding matched source content\n"
        "   - Similarity scores\n"
        "   - Suggested paraphrased alternatives for each plagiarized segment\n\n"
        "4. **Summary Table**:\n"
        "   - Summarized data including total matches and required citations\n\n"
        "5. **Recommendations**:\n"
        "   - Practical steps to improve originality\n"
        "   - Suggestions for paraphrasing and adding citations\n\n"
        "Ensure the report is well-formatted with headings, bullet points, and a professional yet modern design. "
        "Use concise and easy-to-understand language, and visually highlight critical information with bold text or color coding where necessary."
    )

    qa_prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "{context}\n{input}"),
    ])

    try:
        # Assume the LLM object is preloaded
        question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)
        rag_chain = create_retrieval_chain(retriever, question_answer_chain)

        # Input text for detection
        response = rag_chain.invoke({"input": "Detect plagiarism and suggest improvements."})

        # Extract detailed results
        plagiarism_results = response["answer"]



        return plagiarism_results

    except Exception as e:
        raise RuntimeError(f"Error detecting plagiarism: {e}")


if st.button("Paraphrase"):
    output = detect_plagiarism(file, option)
    st.write(output)

